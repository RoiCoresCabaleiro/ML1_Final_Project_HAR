{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "430b036e",
   "metadata": {},
   "source": [
    "Burak Cetin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb509a5",
   "metadata": {},
   "source": [
    "## 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e43fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ML1Utils module with all utility functions\n",
    "include(\"./utils/ML1Utils.jl\")\n",
    "using .ML1Utils\n",
    "\n",
    "# Import additional required packages\n",
    "using Random\n",
    "using DelimitedFiles\n",
    "using Statistics\n",
    "using MLJ\n",
    "using CategoricalArrays\n",
    "using Plots\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "Random.seed!(1234)\n",
    "\n",
    "println(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cc8b4",
   "metadata": {},
   "source": [
    "## 2. Load the HAR Dataset\n",
    "\n",
    "The Human Activity Recognition dataset consists of:\n",
    "- **Training set**: train.csv (70% of data)\n",
    "- **Test set**: test.csv (30% of data)\n",
    "- **561 features**: Time and frequency domain variables from accelerometer and gyroscope\n",
    "- **6 classes**: WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784097cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = readdlm(\"./datasets/train.csv\", ',', header=true)\n",
    "train_matrix = train_data[1]  # Data matrix\n",
    "train_headers = train_data[2]  # Column names\n",
    "\n",
    "# Load test data\n",
    "test_data = readdlm(\"./datasets/test.csv\", ',', header=true)\n",
    "test_matrix = test_data[1]\n",
    "test_headers = test_data[2]\n",
    "\n",
    "println(\"Train data shape: \", size(train_matrix))\n",
    "println(\"Test data shape: \", size(test_matrix))\n",
    "println(\"\\nColumn headers (first 5): \", train_headers[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe6c1f",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "Separate features (X) from labels (y) and prepare the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate inputs (all columns except last) and outputs (last column)\n",
    "X_train = Float32.(train_matrix[:, 1:end-1])\n",
    "y_train = train_matrix[:, end]\n",
    "\n",
    "X_test = Float32.(test_matrix[:, 1:end-1])\n",
    "y_test = test_matrix[:, end]\n",
    "\n",
    "# Get unique classes\n",
    "classes = unique(vcat(y_train, y_test))\n",
    "println(\"Number of features: \", size(X_train, 2))\n",
    "println(\"Number of training samples: \", size(X_train, 1))\n",
    "println(\"Number of test samples: \", size(X_test, 1))\n",
    "println(\"\\nClasses: \", classes)\n",
    "println(\"Number of classes: \", length(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26af6844",
   "metadata": {},
   "source": [
    "### 3.1 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4847c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count samples per class in training set\n",
    "println(\"Training set class distribution:\")\n",
    "for class in classes\n",
    "    count = sum(y_train .== class)\n",
    "    percentage = round(count / length(y_train) * 100, digits=2)\n",
    "    println(\"  $class: $count samples ($percentage%)\")\n",
    "end\n",
    "\n",
    "println(\"\\nTest set class distribution:\")\n",
    "for class in classes\n",
    "    count = sum(y_test .== class)\n",
    "    percentage = round(count / length(y_test) * 100, digits=2)\n",
    "    println(\"  $class: $count samples ($percentage%)\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71251c9",
   "metadata": {},
   "source": [
    "### 3.2 Normalization\n",
    "\n",
    "Although the data is already in [0,1] range, we'll apply min-max normalization to ensure consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7acdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score (ZeroMean) Normalization for PCA compatibility\n",
    "normalization_params = calculateZeroMeanNormalizationParameters(X_train)\n",
    "\n",
    "# Apply normalization to both train and test sets\n",
    "X_train_normalized = normalizeZeroMean(X_train, normalization_params)\n",
    "X_test_normalized = normalizeZeroMean(X_test, normalization_params)\n",
    "\n",
    "println(\"Standardization (Z-Score) completed.\")\n",
    "println(\"Train Mean: \", round(mean(X_train_normalized), digits=2))\n",
    "println(\"Train Std:  \", round(std(X_train_normalized), digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45a703",
   "metadata": {},
   "source": [
    "## 4. Apply PCA - Dimensionality Reduction\n",
    "\n",
    "We'll apply PCA to reduce the 561 features while preserving 95% of the total variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a716f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PCA model from MultivariateStats\n",
    "PCA = MLJ.@load PCA pkg=MultivariateStats verbosity=0\n",
    "\n",
    "# Create PCA model preserving 95% of variance\n",
    "pca_model = PCA(variance_ratio=0.95)\n",
    "\n",
    "# Fit PCA on training data only (important!)\n",
    "pca_machine = machine(pca_model, MLJ.table(X_train_normalized))\n",
    "fit!(pca_machine, verbosity=0)\n",
    "\n",
    "# Transform both training and test data\n",
    "X_train_pca = MLJ.matrix(transform(pca_machine, MLJ.table(X_train_normalized)))\n",
    "X_test_pca = MLJ.matrix(transform(pca_machine, MLJ.table(X_test_normalized)))\n",
    "\n",
    "println(\"PCA Transformation Results:\")\n",
    "println(\"Original dimensions: \", size(X_train_normalized, 2))\n",
    "println(\"Reduced dimensions: \", size(X_train_pca, 2))\n",
    "println(\"Dimensionality reduction: \", round((1 - size(X_train_pca, 2)/size(X_train_normalized, 2))*100, digits=2), \"%\")\n",
    "println(\"\\nTrain set shape: \", size(X_train_pca))\n",
    "println(\"Test set shape: \", size(X_test_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bfe374",
   "metadata": {},
   "source": [
    "### 4.1 PCA Variance Threshold Analysis\n",
    "\n",
    "Before selecting the final variance ratio, let's compare different thresholds to justify our choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37367b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different variance ratio thresholds\n",
    "println(\"PCA Variance Threshold Comparison:\")\n",
    "println(\"=\"^60)\n",
    "println(\"\\nOriginal dimensions: 561 features\")\n",
    "println(\"\\nTesting different variance preservation thresholds:\")\n",
    "\n",
    "variance_thresholds = [0.90, 0.95, 0.99]\n",
    "threshold_results = []\n",
    "\n",
    "for variance_ratio in variance_thresholds\n",
    "    pca_test = PCA(variance_ratio=variance_ratio)\n",
    "    pca_mach_test = machine(pca_test, MLJ.table(X_train_normalized))\n",
    "    fit!(pca_mach_test, verbosity=0)\n",
    "    X_temp = MLJ.matrix(transform(pca_mach_test, MLJ.table(X_train_normalized)))\n",
    "    \n",
    "    n_components = size(X_temp, 2)\n",
    "    reduction_pct = round((1 - n_components/561)*100, digits=2)\n",
    "    \n",
    "    println(\"\\nVariance ratio = $(variance_ratio):\")\n",
    "    println(\"  Components retained: $n_components\")\n",
    "    println(\"  Dimensionality reduction: $reduction_pct%\")\n",
    "    println(\"  Features removed: $(561 - n_components)\")\n",
    "    \n",
    "    push!(threshold_results, (ratio=variance_ratio, components=n_components, reduction=reduction_pct))\n",
    "end\n",
    "\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Selected variance_ratio: 0.99\")\n",
    "println(\"Rationale: Balances information preservation with dimensionality reduction\")\n",
    "println(\"=\"^60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22cf0d4",
   "metadata": {},
   "source": [
    "### 4.2 Visualize PCA Results (2D Projection)\n",
    "\n",
    "Let's create a 2D visualization to see how well PCA separates the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95fcfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate PCA model with only 2 components for visualization\n",
    "pca_2d = PCA(maxoutdim=2)\n",
    "pca_2d_mach = machine(pca_2d, MLJ.table(X_train_normalized))\n",
    "fit!(pca_2d_mach, verbosity=0)\n",
    "\n",
    "# Transform to 2D\n",
    "X_train_2d = MLJ.matrix(transform(pca_2d_mach, MLJ.table(X_train_normalized)))\n",
    "\n",
    "# Create scatter plot\n",
    "plot_fig = plot(title=\"PCA Projection (2D) - HAR Dataset\",\n",
    "                xlabel=\"First Principal Component\",\n",
    "                ylabel=\"Second Principal Component\",\n",
    "                legend=:outertopright)\n",
    "\n",
    "colors = [:red, :blue, :green, :orange, :purple, :brown]\n",
    "for (i, class) in enumerate(classes)\n",
    "    mask = y_train .== class\n",
    "    scatter!(plot_fig, X_train_2d[mask, 1], X_train_2d[mask, 2],\n",
    "             label=string(class), markersize=3, alpha=0.6, color=colors[i])\n",
    "end\n",
    "\n",
    "display(plot_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb824f8",
   "metadata": {},
   "source": [
    "## 5. Prepare Data for Models\n",
    "\n",
    "Convert labels to the appropriate format for each model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c3c711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MLJ models (SVM, DT, kNN): Use categorical labels with shared pool\n",
    "all_labels = categorical(vcat(y_train, y_test))\n",
    "y_train_cat = all_labels[1:length(y_train)]\n",
    "y_test_cat = all_labels[length(y_train)+1:end]\n",
    "\n",
    "# For ANN: Use one-hot encoding\n",
    "y_train_onehot = oneHotEncoding(y_train, classes)\n",
    "y_test_onehot = oneHotEncoding(y_test, classes)\n",
    "\n",
    "println(\"Labels prepared:\")\n",
    "println(\"Categorical labels shape: \", length(y_train_cat), \" (train), \", length(y_test_cat), \" (test)\")\n",
    "println(\"One-hot encoded shape: \", size(y_train_onehot), \" (train), \", size(y_test_onehot), \" (test)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8059dd9e",
   "metadata": {},
   "source": [
    "## 6. Cross-Validation Setup\n",
    "\n",
    "Create stratified k-fold cross-validation indices for model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b686491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10-fold stratified cross-validation indices\n",
    "k_folds = 10\n",
    "cv_indices = crossvalidation(y_train, k_folds)\n",
    "\n",
    "println(\"Cross-validation setup:\")\n",
    "println(\"Number of folds: \", k_folds)\n",
    "println(\"CV indices length: \", length(cv_indices))\n",
    "println(\"\\nSamples per fold:\")\n",
    "for fold in 1:k_folds\n",
    "    count = sum(cv_indices .== fold)\n",
    "    println(\"  Fold $fold: $count samples\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b051ab3d",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "Now we'll train all 4 required models on the PCA-reduced features.\n",
    "\n",
    "### 7.1 Artificial Neural Networks (ANNs)\n",
    "\n",
    "Test at least 8 different architectures (1-2 hidden layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ea11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 8+ ANN architectures to test\n",
    "ann_topologies = [\n",
    "    [10],           # Single layer - 10 neurons\n",
    "    [20],           # Single layer - 20 neurons\n",
    "    [50],           # Single layer - 50 neurons\n",
    "    [100],          # Single layer - 100 neurons\n",
    "    [50, 25],       # Two layers - 50, 25 neurons\n",
    "    [100, 50],      # Two layers - 100, 50 neurons\n",
    "    [100, 50, 25],  # Three layers - 100, 50, 25 neurons\n",
    "    [200, 100],     # Two layers - 200, 100 neurons\n",
    "]\n",
    "\n",
    "println(\"ANN architectures to test: \", length(ann_topologies))\n",
    "for (i, topology) in enumerate(ann_topologies)\n",
    "    println(\"  Architecture $i: \", topology)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e87672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train ANNs with cross-validation\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Training ANNs with Cross-Validation\")\n",
    "println(\"=\"^60 * \"\\n\")\n",
    "\n",
    "ann_results = []\n",
    "\n",
    "for (i, topology) in enumerate(ann_topologies)\n",
    "    println(\"\\nTesting ANN Architecture $i: \", topology)\n",
    "    \n",
    "    # Track training time\n",
    "    training_time = @elapsed begin\n",
    "        # Run cross-validation\n",
    "        results = ANNCrossValidation(\n",
    "            topology,\n",
    "            (X_train_pca, y_train),\n",
    "            cv_indices,\n",
    "            numExecutions=5,\n",
    "            maxEpochs=100,\n",
    "            learningRate=0.01,\n",
    "            validationRatio=0.2,\n",
    "            maxEpochsVal=10\n",
    "        )\n",
    "    end\n",
    "    \n",
    "    # Extract all metrics (comprehensive display)\n",
    "    acc_mean, acc_std = results[1]\n",
    "    err_mean, err_std = results[2]\n",
    "    sens_mean, sens_std = results[3]\n",
    "    spec_mean, spec_std = results[4]\n",
    "    ppv_mean, ppv_std = results[5]\n",
    "    npv_mean, npv_std = results[6]\n",
    "    f1_mean, f1_std = results[7]\n",
    "    \n",
    "    println(\"  Training time: $(round(training_time, digits=2))s\")\n",
    "    println(\"  Accuracy:     $(round(acc_mean*100, digits=2))% ± $(round(acc_std*100, digits=2))%\")\n",
    "    println(\"  Error Rate:   $(round(err_mean*100, digits=2))% ± $(round(err_std*100, digits=2))%\")\n",
    "    println(\"  Sensitivity:  $(round(sens_mean, digits=4)) ± $(round(sens_std, digits=4))\")\n",
    "    println(\"  Specificity:  $(round(spec_mean, digits=4)) ± $(round(spec_std, digits=4))\")\n",
    "    println(\"  PPV:          $(round(ppv_mean, digits=4)) ± $(round(ppv_std, digits=4))\")\n",
    "    println(\"  NPV:          $(round(npv_mean, digits=4)) ± $(round(npv_std, digits=4))\")\n",
    "    println(\"  F1-Score:     $(round(f1_mean, digits=4)) ± $(round(f1_std, digits=4))\")\n",
    "    \n",
    "    push!(ann_results, (topology=topology, accuracy=acc_mean, f1=f1_mean, time=training_time, results=results))\n",
    "end\n",
    "\n",
    "# Find best ANN architecture\n",
    "best_ann = argmax([r.accuracy for r in ann_results])\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Best ANN Architecture: \", ann_results[best_ann].topology)\n",
    "println(\"Best Accuracy: \", round(ann_results[best_ann].accuracy*100, digits=2), \"%\")\n",
    "println(\"Training Time: \", round(ann_results[best_ann].time, digits=2), \"s\")\n",
    "println(\"=\"^60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb4a99e",
   "metadata": {},
   "source": [
    "### 7.2 Support Vector Machines (SVMs)\n",
    "\n",
    "Test at least 8 different configurations with various kernels and C values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2fd49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 8+ SVM configurations\n",
    "svm_configs = [\n",
    "    Dict(\"kernel\" => \"linear\", \"C\" => 0.1),\n",
    "    Dict(\"kernel\" => \"linear\", \"C\" => 1.0),\n",
    "    Dict(\"kernel\" => \"linear\", \"C\" => 10.0),\n",
    "    Dict(\"kernel\" => \"rbf\", \"C\" => 0.1, \"gamma\" => 0.01),\n",
    "    Dict(\"kernel\" => \"rbf\", \"C\" => 1.0, \"gamma\" => 0.01),\n",
    "    Dict(\"kernel\" => \"rbf\", \"C\" => 10.0, \"gamma\" => 0.01),\n",
    "    Dict(\"kernel\" => \"poly\", \"C\" => 1.0, \"degree\" => 2),\n",
    "    Dict(\"kernel\" => \"poly\", \"C\" => 1.0, \"degree\" => 3),\n",
    "]\n",
    "\n",
    "println(\"SVM configurations to test: \", length(svm_configs))\n",
    "for (i, config) in enumerate(svm_configs)\n",
    "    println(\"  Config $i: \", config)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ee7d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train SVMs with cross-validation\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Training SVMs with Cross-Validation\")\n",
    "println(\"=\"^60 * \"\\n\")\n",
    "\n",
    "svm_results = []\n",
    "\n",
    "for (i, config) in enumerate(svm_configs)\n",
    "    println(\"\\nTesting SVM Config $i: \", config)\n",
    "    \n",
    "    training_time = @elapsed begin\n",
    "        results = modelCrossValidation(\n",
    "            :SVC,\n",
    "            config,\n",
    "            (X_train_pca, y_train),\n",
    "            cv_indices\n",
    "        )\n",
    "    end\n",
    "    \n",
    "    # Extract all metrics\n",
    "    acc_mean, acc_std = results[1]\n",
    "    err_mean, err_std = results[2]\n",
    "    sens_mean, sens_std = results[3]\n",
    "    spec_mean, spec_std = results[4]\n",
    "    ppv_mean, ppv_std = results[5]\n",
    "    npv_mean, npv_std = results[6]\n",
    "    f1_mean, f1_std = results[7]\n",
    "    \n",
    "    println(\"  Training time: $(round(training_time, digits=2))s\")\n",
    "    println(\"  Accuracy:     $(round(acc_mean*100, digits=2))% ± $(round(acc_std*100, digits=2))%\")\n",
    "    println(\"  F1-Score:     $(round(f1_mean, digits=4)) ± $(round(f1_std, digits=4))\")\n",
    "    \n",
    "    push!(svm_results, (config=config, accuracy=acc_mean, f1=f1_mean, time=training_time, results=results))\n",
    "end\n",
    "\n",
    "# Find best SVM configuration\n",
    "best_svm = argmax([r.accuracy for r in svm_results])\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Best SVM Configuration: \", svm_results[best_svm].config)\n",
    "println(\"Best Accuracy: \", round(svm_results[best_svm].accuracy*100, digits=2), \"%\")\n",
    "println(\"Training Time: \", round(svm_results[best_svm].time, digits=2), \"s\")\n",
    "println(\"=\"^60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3697f46",
   "metadata": {},
   "source": [
    "### 7.3 Decision Trees\n",
    "\n",
    "Test at least 6 different maximum depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e078937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 6+ Decision Tree configurations\n",
    "dt_max_depths = [2, 4, 6, 8, 10, 15, 20, -1]  # -1 means no limit\n",
    "\n",
    "println(\"Decision Tree max_depth values to test: \", length(dt_max_depths))\n",
    "println(dt_max_depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1569e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Decision Trees with cross-validation\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Training Decision Trees with Cross-Validation\")\n",
    "println(\"=\"^60 * \"\\n\")\n",
    "\n",
    "dt_results = []\n",
    "\n",
    "for max_depth in dt_max_depths\n",
    "    depth_str = max_depth == -1 ? \"unlimited\" : string(max_depth)\n",
    "    println(\"\\nTesting Decision Tree with max_depth=$depth_str\")\n",
    "    \n",
    "    training_time = @elapsed begin\n",
    "        results = modelCrossValidation(\n",
    "            :DecisionTreeClassifier,\n",
    "            Dict(\"max_depth\" => max_depth, \"seed\" => 42),\n",
    "            (X_train_pca, y_train),\n",
    "            cv_indices\n",
    "        )\n",
    "    end\n",
    "    \n",
    "    acc_mean, acc_std = results[1]\n",
    "    f1_mean, f1_std = results[7]\n",
    "    \n",
    "    println(\"  Training time: $(round(training_time, digits=2))s\")\n",
    "    println(\"  Accuracy:     $(round(acc_mean*100, digits=2))% ± $(round(acc_std*100, digits=2))%\")\n",
    "    println(\"  F1-Score:     $(round(f1_mean, digits=4)) ± $(round(f1_std, digits=4))\")\n",
    "    \n",
    "    push!(dt_results, (max_depth=max_depth, accuracy=acc_mean, f1=f1_mean, time=training_time, results=results))\n",
    "end\n",
    "\n",
    "# Find best Decision Tree depth\n",
    "best_dt = argmax([r.accuracy for r in dt_results])\n",
    "best_depth_str = dt_results[best_dt].max_depth == -1 ? \"unlimited\" : string(dt_results[best_dt].max_depth)\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Best Decision Tree max_depth: \", best_depth_str)\n",
    "println(\"Best Accuracy: \", round(dt_results[best_dt].accuracy*100, digits=2), \"%\")\n",
    "println(\"Training Time: \", round(dt_results[best_dt].time, digits=2), \"s\")\n",
    "println(\"=\"^60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cbdc5e",
   "metadata": {},
   "source": [
    "### 7.4 k-Nearest Neighbors (kNN)\n",
    "\n",
    "Test at least 6 different k values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeee49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 6+ kNN configurations\n",
    "knn_k_values = [1, 3, 5, 7, 9, 11, 15, 21]\n",
    "\n",
    "println(\"kNN k values to test: \", length(knn_k_values))\n",
    "println(knn_k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204b9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train kNN with cross-validation\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Training kNN with Cross-Validation\")\n",
    "println(\"=\"^60 * \"\\n\")\n",
    "\n",
    "knn_results = []\n",
    "\n",
    "for k in knn_k_values\n",
    "    println(\"\\nTesting kNN with k=$k\")\n",
    "    \n",
    "    training_time = @elapsed begin\n",
    "        results = modelCrossValidation(\n",
    "            :KNNClassifier,\n",
    "            Dict(\"K\" => k),\n",
    "            (X_train_pca, y_train),\n",
    "            cv_indices\n",
    "        )\n",
    "    end\n",
    "    \n",
    "    acc_mean, acc_std = results[1]\n",
    "    f1_mean, f1_std = results[7]\n",
    "    \n",
    "    println(\"  Training time: $(round(training_time, digits=2))s\")\n",
    "    println(\"  Accuracy:     $(round(acc_mean*100, digits=2))% ± $(round(acc_std*100, digits=2))%\")\n",
    "    println(\"  F1-Score:     $(round(f1_mean, digits=4)) ± $(round(f1_std, digits=4))\")\n",
    "    \n",
    "    push!(knn_results, (k=k, accuracy=acc_mean, f1=f1_mean, time=training_time, results=results))\n",
    "end\n",
    "\n",
    "# Find best kNN k value\n",
    "best_knn = argmax([r.accuracy for r in knn_results])\n",
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Best kNN k value: \", knn_results[best_knn].k)\n",
    "println(\"Best Accuracy: \", round(knn_results[best_knn].accuracy*100, digits=2), \"%\")\n",
    "println(\"Training Time: \", round(knn_results[best_knn].time, digits=2), \"s\")\n",
    "println(\"=\"^60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39439d",
   "metadata": {},
   "source": [
    "## 8. Summary of Cross-Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e361c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validation results\n",
    "using Plots\n",
    "\n",
    "# ANN architectures comparison\n",
    "ann_accs = [r.accuracy * 100 for r in ann_results]\n",
    "ann_labels = [string(r.topology) for r in ann_results]\n",
    "\n",
    "p1 = bar(1:length(ann_accs), ann_accs,\n",
    "         title=\"ANN Architectures - CV Accuracy\",\n",
    "         ylabel=\"Accuracy (%)\",\n",
    "         xlabel=\"Architecture\",\n",
    "         xticks=(1:length(ann_labels), ann_labels),\n",
    "         xrotation=45,\n",
    "         legend=false,\n",
    "         color=:lightblue,\n",
    "         ylim=(90, 100))\n",
    "\n",
    "# SVM configurations comparison\n",
    "svm_accs = [r.accuracy * 100 for r in svm_results]\n",
    "svm_labels = [string(r.config[\"kernel\"], \" C=\", r.config[\"C\"]) for r in svm_results]\n",
    "\n",
    "p2 = bar(1:length(svm_accs), svm_accs,\n",
    "         title=\"SVM Configurations - CV Accuracy\",\n",
    "         ylabel=\"Accuracy (%)\",\n",
    "         xlabel=\"Configuration\",\n",
    "         xticks=(1:length(svm_labels), svm_labels),\n",
    "         xrotation=45,\n",
    "         legend=false,\n",
    "         color=:lightgreen,\n",
    "         ylim=(90, 100))\n",
    "\n",
    "# Decision Tree depths comparison\n",
    "dt_accs = [r.accuracy * 100 for r in dt_results]\n",
    "dt_labels = [r.max_depth == -1 ? \"unlimited\" : string(r.max_depth) for r in dt_results]\n",
    "\n",
    "p3 = bar(1:length(dt_accs), dt_accs,\n",
    "         title=\"Decision Tree Depths - CV Accuracy\",\n",
    "         ylabel=\"Accuracy (%)\",\n",
    "         xlabel=\"Max Depth\",\n",
    "         xticks=(1:length(dt_labels), dt_labels),\n",
    "         legend=false,\n",
    "         color=:orange,\n",
    "         fillcolor=:orange,\n",
    "         linecolor=:orange)\n",
    "\n",
    "# kNN k values comparison\n",
    "knn_accs = [r.accuracy * 100 for r in knn_results]\n",
    "knn_labels = [string(\"k=\", r.k) for r in knn_results]\n",
    "\n",
    "p4 = bar(1:length(knn_accs), knn_accs,\n",
    "         title=\"kNN k Values - CV Accuracy\",\n",
    "         ylabel=\"Accuracy (%)\",\n",
    "         xlabel=\"k Value\",\n",
    "         xticks=(1:length(knn_labels), knn_labels),\n",
    "         legend=false,\n",
    "         color=:lightcoral,\n",
    "         ylim=(90, 100))\n",
    "\n",
    "plot(p1, p2, p3, p4, layout=(2, 2), size=(1200, 800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2679de",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\n\" * \"=\"^80)\n",
    "println(\"CROSS-VALIDATION RESULTS SUMMARY (PCA Approach)\")\n",
    "println(\"=\"^80)\n",
    "\n",
    "println(\"\\nBest ANN:\")\n",
    "println(\"  Architecture: \", ann_results[best_ann].topology)\n",
    "println(\"  CV Accuracy: \", round(ann_results[best_ann].accuracy*100, digits=2), \"%\")\n",
    "\n",
    "println(\"\\nBest SVM:\")\n",
    "println(\"  Configuration: \", svm_results[best_svm].config)\n",
    "println(\"  CV Accuracy: \", round(svm_results[best_svm].accuracy*100, digits=2), \"%\")\n",
    "\n",
    "println(\"\\nBest Decision Tree:\")\n",
    "best_dt_depth_str = dt_results[best_dt].max_depth == -1 ? \"unlimited\" : string(dt_results[best_dt].max_depth)\n",
    "println(\"  Max Depth: \", best_dt_depth_str)\n",
    "println(\"  CV Accuracy: \", round(dt_results[best_dt].accuracy*100, digits=2), \"%\")\n",
    "\n",
    "println(\"\\nBest kNN:\")\n",
    "println(\"  k value: \", knn_results[best_knn].k)\n",
    "println(\"  CV Accuracy: \", round(knn_results[best_knn].accuracy*100, digits=2), \"%\")\n",
    "\n",
    "println(\"\\n\" * \"=\"^80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145aa83a",
   "metadata": {},
   "source": [
    "## 9. Train Final Models on Full Training Set\n",
    "\n",
    "Now train the best configurations on the entire training set and evaluate on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\nTraining final models on full training set...\\n\")\n",
    "\n",
    "# Will store final test results here\n",
    "final_results = Dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf41f1",
   "metadata": {},
   "source": [
    "### 9.1 Train Final ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6959955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best ANN on full training set\n",
    "best_topology = ann_results[best_ann].topology\n",
    "println(\"Training final ANN with topology: \", best_topology)\n",
    "\n",
    "# Create a randomized split using holdOut: 90% Training, 10% Validation\n",
    "N_patterns = size(X_train_pca, 1)\n",
    "(train_indices, val_indices) = holdOut(N_patterns, 0.1)\n",
    "\n",
    "# Apply indices to create the physical datasets\n",
    "X_train_final = X_train_pca[train_indices, :]\n",
    "y_train_final = y_train_onehot[train_indices, :]\n",
    "\n",
    "X_val_final = X_train_pca[val_indices, :]\n",
    "y_val_final = y_train_onehot[val_indices, :]\n",
    "\n",
    "println(\"Data Split Completed:\")\n",
    "println(\"  Final Training Samples: \", size(X_train_final, 1))\n",
    "println(\"  Validation Samples:     \", size(X_val_final, 1))\n",
    "\n",
    "final_ann, _, _, _ = trainClassANN(\n",
    "    best_topology,\n",
    "    (X_train_final, y_train_final),\n",
    "    validationDataset=(X_val_final, y_val_final),\n",
    "    maxEpochs=200,\n",
    "    learningRate=0.01,\n",
    "    maxEpochsVal=20,\n",
    "    showText=false\n",
    ")\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred_ann = final_ann(X_test_pca')'\n",
    "acc, err, sens, spec, ppv, npv, f1, cm = confusionMatrix(y_pred_ann, y_test_onehot)\n",
    "\n",
    "final_results[\"ANN\"] = Dict(\n",
    "    \"accuracy\" => acc,\n",
    "    \"f1\" => f1,\n",
    "    \"confusion_matrix\" => cm\n",
    ")\n",
    "\n",
    "println(\"\\nANN Test Results:\")\n",
    "println(\"  Accuracy: \", round(acc*100, digits=2), \"%\")\n",
    "println(\"  F1-Score: \", round(f1, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830413e4",
   "metadata": {},
   "source": [
    "### 9.2 Train Final SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680fcbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best SVM on full training set\n",
    "best_svm_config = svm_results[best_svm].config\n",
    "println(\"\\nTraining final SVM with config: \", best_svm_config)\n",
    "\n",
    "SVC = MLJ.@load SVC pkg=LIBSVM\n",
    "import LIBSVM  # Import LIBSVM to access kernel types\n",
    "\n",
    "kernel_str = best_svm_config[\"kernel\"]\n",
    "kernel = kernel_str == \"linear\" ? LIBSVM.Kernel.Linear :\n",
    "         kernel_str == \"rbf\" ? LIBSVM.Kernel.RadialBasis :\n",
    "         kernel_str == \"poly\" ? LIBSVM.Kernel.Polynomial : LIBSVM.Kernel.RadialBasis\n",
    "\n",
    "svm_model = SVC(\n",
    "    kernel=kernel,\n",
    "    cost=Float64(best_svm_config[\"C\"]),\n",
    "    gamma=Float64(get(best_svm_config, \"gamma\", 0.01)),\n",
    "    degree=Int32(get(best_svm_config, \"degree\", 3))\n",
    ")\n",
    "\n",
    "svm_mach = machine(svm_model, MLJ.table(X_train_pca), y_train_cat)\n",
    "fit!(svm_mach, verbosity=0)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_svm = predict(svm_mach, MLJ.table(X_test_pca))\n",
    "y_pred_svm_labels = string.(y_pred_svm)\n",
    "\n",
    "acc, err, sens, spec, ppv, npv, f1, cm = confusionMatrix(y_pred_svm_labels, string.(y_test), classes)\n",
    "\n",
    "final_results[\"SVM\"] = Dict(\n",
    "    \"accuracy\" => acc,\n",
    "    \"f1\" => f1,\n",
    "    \"confusion_matrix\" => cm\n",
    ")\n",
    "\n",
    "println(\"\\nSVM Test Results:\")\n",
    "println(\"  Accuracy: \", round(acc*100, digits=2), \"%\")\n",
    "println(\"  F1-Score: \", round(f1, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba55e14",
   "metadata": {},
   "source": [
    "### 9.3 Train Final Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbd0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best Decision Tree on full training set\n",
    "best_dt_depth = dt_results[best_dt].max_depth\n",
    "println(\"\\nTraining final Decision Tree with max_depth: \", best_dt_depth)\n",
    "\n",
    "DTClassifier = MLJ.@load DecisionTreeClassifier pkg=DecisionTree\n",
    "dt_model = DTClassifier(max_depth=best_dt_depth, rng=Random.MersenneTwister(42))\n",
    "\n",
    "dt_mach = machine(dt_model, MLJ.table(X_train_pca), y_train_cat)\n",
    "fit!(dt_mach, verbosity=0)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_dt = predict(dt_mach, MLJ.table(X_test_pca))\n",
    "y_pred_dt_labels = string.(mode.(y_pred_dt))\n",
    "\n",
    "acc, err, sens, spec, ppv, npv, f1, cm = confusionMatrix(y_pred_dt_labels, string.(y_test), classes)\n",
    "\n",
    "final_results[\"DT\"] = Dict(\n",
    "    \"accuracy\" => acc,\n",
    "    \"f1\" => f1,\n",
    "    \"confusion_matrix\" => cm\n",
    ")\n",
    "\n",
    "println(\"\\nDecision Tree Test Results:\")\n",
    "println(\"  Accuracy: \", round(acc*100, digits=2), \"%\")\n",
    "println(\"  F1-Score: \", round(f1, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef886941",
   "metadata": {},
   "source": [
    "### 9.4 Train Final kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c08b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train best kNN on full training set\n",
    "best_k = knn_results[best_knn].k\n",
    "println(\"\\nTraining final kNN with k: \", best_k)\n",
    "\n",
    "KNNClassifier = MLJ.@load KNNClassifier pkg=NearestNeighborModels\n",
    "knn_model = KNNClassifier(K=best_k)\n",
    "\n",
    "knn_mach = machine(knn_model, MLJ.table(X_train_pca), y_train_cat)\n",
    "fit!(knn_mach, verbosity=0)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_knn = predict(knn_mach, MLJ.table(X_test_pca))\n",
    "y_pred_knn_labels = string.(mode.(y_pred_knn))\n",
    "\n",
    "acc, err, sens, spec, ppv, npv, f1, cm = confusionMatrix(y_pred_knn_labels, string.(y_test), classes)\n",
    "\n",
    "final_results[\"kNN\"] = Dict(\n",
    "    \"accuracy\" => acc,\n",
    "    \"f1\" => f1,\n",
    "    \"confusion_matrix\" => cm\n",
    ")\n",
    "\n",
    "println(\"\\nkNN Test Results:\")\n",
    "println(\"  Accuracy: \", round(acc*100, digits=2), \"%\")\n",
    "println(\"  F1-Score: \", round(f1, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514cfcd0",
   "metadata": {},
   "source": [
    "## 10. Ensemble Model (Voting Classifier)\n",
    "\n",
    "Combine the 3 best individual models using majority voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb18859",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Creating Ensemble Model (Voting Classifier)\")\n",
    "println(\"=\"^60 * \"\\n\")\n",
    "\n",
    "# Get predictions from all models (as strings)\n",
    "pred_svm_str = y_pred_svm_labels\n",
    "pred_dt_str = y_pred_dt_labels\n",
    "pred_knn_str = y_pred_knn_labels\n",
    "\n",
    "# Convert ANN predictions to class labels\n",
    "pred_ann_onehot = classifyOutputs(y_pred_ann)\n",
    "pred_ann_str = [classes[findfirst(pred_ann_onehot[i, :])] for i in 1:size(pred_ann_onehot, 1)]\n",
    "\n",
    "# Simple majority voting\n",
    "function majority_vote(preds...)\n",
    "    votes = Dict()\n",
    "    for pred in preds\n",
    "        votes[pred] = get(votes, pred, 0) + 1\n",
    "    end\n",
    "    return argmax(votes)\n",
    "end\n",
    "\n",
    "y_pred_ensemble = [majority_vote(pred_svm_str[i], pred_dt_str[i], pred_knn_str[i]) \n",
    "                   for i in 1:length(y_test)]\n",
    "\n",
    "# Evaluate ensemble\n",
    "acc, err, sens, spec, ppv, npv, f1, cm = confusionMatrix(y_pred_ensemble, string.(y_test), classes)\n",
    "\n",
    "final_results[\"Ensemble\"] = Dict(\n",
    "    \"accuracy\" => acc,\n",
    "    \"f1\" => f1,\n",
    "    \"confusion_matrix\" => cm\n",
    ")\n",
    "\n",
    "println(\"\\nEnsemble Test Results:\")\n",
    "println(\"  Accuracy: \", round(acc*100, digits=2), \"%\")\n",
    "println(\"  F1-Score: \", round(f1, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899b6749",
   "metadata": {},
   "source": [
    "## 11. Final Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"\\n\" * \"=\"^60)\n",
    "println(\"Creating Optimized Ensemble (ANN + SVM + kNN)\")\n",
    "println(\"=\"^60 * \"\\n\")\n",
    "\n",
    "# Convert ANN predictions to class labels (from one-hot to string)\n",
    "# Ensure y_pred_ann variable exists in memory from the previous step\n",
    "pred_ann_onehot = classifyOutputs(y_pred_ann)\n",
    "pred_ann_str = [classes[findfirst(pred_ann_onehot[i, :])] for i in 1:size(pred_ann_onehot, 1)]\n",
    "\n",
    "# Get predictions from other top-performing models\n",
    "# We use SVM and kNN. We exclude Decision Tree due to lower performance.\n",
    "pred_svm_str = y_pred_svm_labels\n",
    "pred_knn_str = y_pred_knn_labels\n",
    "\n",
    "# Define Majority Voting Function\n",
    "function majority_vote(preds...)\n",
    "    votes = Dict()\n",
    "    for pred in preds\n",
    "        votes[pred] = get(votes, pred, 0) + 1\n",
    "    end\n",
    "    # Return the label with the most votes\n",
    "    return argmax(votes)\n",
    "end\n",
    "\n",
    "# Apply voting for each test sample\n",
    "# The ensemble combines: ANN + SVM + kNN \n",
    "y_pred_ensemble = [majority_vote(pred_ann_str[i], pred_svm_str[i], pred_knn_str[i]) \n",
    "                   for i in 1:length(y_test)]\n",
    "\n",
    "# Evaluate the Ensemble Model\n",
    "acc, err, sens, spec, ppv, npv, f1, cm = confusionMatrix(y_pred_ensemble, string.(y_test), classes)\n",
    "\n",
    "final_results[\"Ensemble\"] = Dict(\n",
    "    \"accuracy\" => acc,\n",
    "    \"f1\" => f1,\n",
    "    \"confusion_matrix\" => cm\n",
    ")\n",
    "\n",
    "println(\"Ensemble Test Accuracy: \", round(acc*100, digits=2), \"%\")\n",
    "println(\"Ensemble F1-Score: \", round(f1, digits=4))\n",
    "\n",
    "println(\"\\n\" * \"=\"^80)\n",
    "println(\"FINAL TEST SET RESULTS - PCA APPROACH (Z-Score + 95% Variance)\")\n",
    "println(\"=\"^80)\n",
    "\n",
    "# Sort models by accuracy (descending) and print results\n",
    "for (model_name, results) in sort(collect(final_results), by=x->x[2][\"accuracy\"], rev=true)\n",
    "    acc = results[\"accuracy\"]\n",
    "    f1 = results[\"f1\"]\n",
    "    println(rpad(model_name, 15), \"Accuracy: \", rpad(round(acc*100, digits=2), 6), \"%   \", \"F1-Score: \", round(f1, digits=4))\n",
    "end\n",
    "println(\"=\"^80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a57d096",
   "metadata": {},
   "source": [
    "## 12. Visualization: Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e040134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model performance comparison\n",
    "using Plots\n",
    "\n",
    "model_names = [\"ANN\", \"SVM\", \"DT\", \"kNN\", \"Ensemble\"]\n",
    "accuracies = [final_results[name][\"accuracy\"]*100 for name in model_names]\n",
    "f1_scores = [final_results[name][\"f1\"] for name in model_names]\n",
    "\n",
    "# Create bar plots\n",
    "p1 = bar(model_names, accuracies, \n",
    "         title=\"Test Set Accuracy Comparison\",\n",
    "         ylabel=\"Accuracy (%)\",\n",
    "         xlabel=\"Model\",\n",
    "         legend=false,\n",
    "         color=:steelblue,\n",
    "         ylim=(0, 100))\n",
    "\n",
    "# Add value labels on bars\n",
    "for (i, acc) in enumerate(accuracies)\n",
    "    annotate!(i, acc + 2, text(string(round(acc, digits=2), \"%\"), 8))\n",
    "end\n",
    "\n",
    "p2 = bar(model_names, f1_scores,\n",
    "         title=\"Test Set F1-Score Comparison\", \n",
    "         ylabel=\"F1-Score\",\n",
    "         xlabel=\"Model\",\n",
    "         legend=false,\n",
    "         color=:coral,\n",
    "         ylim=(0, 1))\n",
    "\n",
    "# Add value labels on bars\n",
    "for (i, f1) in enumerate(f1_scores)\n",
    "    annotate!(i, f1 + 0.05, text(string(round(f1, digits=4)), 8))\n",
    "end\n",
    "\n",
    "plot(p1, p2, layout=(1, 2), size=(1000, 400))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5a721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print confusion matrices for all models\n",
    "for (model_name, results) in final_results\n",
    "    println(\"\\n\" * \"=\"^60)\n",
    "    println(\"Confusion Matrix - \", model_name)\n",
    "    println(\"=\"^60)\n",
    "    println(results[\"confusion_matrix\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrices as heatmaps\n",
    "using Plots\n",
    "\n",
    "# Function to plot confusion matrix heatmap\n",
    "function plot_confusion_matrix(cm, class_labels, title_text)\n",
    "    n = length(class_labels)\n",
    "    \n",
    "    p = heatmap(1:n, 1:n, cm,\n",
    "                aspect_ratio=:equal,\n",
    "                c=:Blues,\n",
    "                xlabel=\"Predicted\",\n",
    "                ylabel=\"Actual\",\n",
    "                title=title_text,\n",
    "                xticks=(1:n, class_labels),\n",
    "                yticks=(1:n, class_labels),\n",
    "                xrotation=45,\n",
    "                size=(500, 450),\n",
    "                yflip=true)\n",
    "    \n",
    "    # Add text annotations\n",
    "    for i in 1:n\n",
    "        for j in 1:n\n",
    "            val = Int(round(cm[i, j]))\n",
    "            annotate!(p, j, i, text(string(val), 9, :white, :center))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return p\n",
    "end\n",
    "\n",
    "# Plot all confusion matrices in a specific order\n",
    "model_order = [\"ANN\", \"SVM\", \"DT\", \"kNN\", \"Ensemble\"]\n",
    "plots_cm = []\n",
    "\n",
    "for model_name in model_order\n",
    "    if haskey(final_results, model_name)\n",
    "        cm = final_results[model_name][\"confusion_matrix\"]\n",
    "        p = plot_confusion_matrix(cm, string.(classes), \"CM - $model_name\")\n",
    "        push!(plots_cm, p)\n",
    "    end\n",
    "end\n",
    "\n",
    "plot(plots_cm..., layout=(2, 3), size=(1400, 900))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2f564d",
   "metadata": {},
   "source": [
    "### 12.1 Per-Class Performance Analysis\n",
    "\n",
    "Analyze confusion matrices to extract per-class metrics (Precision, Recall, F1-Score) for each activity type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d69b368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute per-class metrics from confusion matrix\n",
    "function analyze_confusion_matrix(cm, class_labels, model_name)\n",
    "    n_classes = length(class_labels)\n",
    "    \n",
    "    println(\"\\n\" * \"=\"^80)\n",
    "    println(\"Per-Class Performance Analysis - $model_name\")\n",
    "    println(\"=\"^80)\n",
    "    println(\"\\n\", rpad(\"Activity\", 20), rpad(\"Precision\", 12), rpad(\"Recall\", 12), rpad(\"F1-Score\", 12), \"Support\")\n",
    "    println(\"-\"^80)\n",
    "    \n",
    "    for i in 1:n_classes\n",
    "        # True Positives, False Positives, False Negatives\n",
    "        tp = cm[i, i]\n",
    "        fp = sum(cm[:, i]) - tp\n",
    "        fn = sum(cm[i, :]) - tp\n",
    "        support = sum(cm[i, :])\n",
    "        \n",
    "        # Precision, Recall, F1 per class\n",
    "        precision = tp > 0 ? tp / (tp + fp) : 0.0\n",
    "        recall = tp > 0 ? tp / (tp + fn) : 0.0\n",
    "        f1 = (precision + recall) > 0 ? 2 * (precision * recall) / (precision + recall) : 0.0\n",
    "        \n",
    "        println(rpad(string(class_labels[i]), 20), \n",
    "                rpad(round(precision, digits=4), 12), \n",
    "                rpad(round(recall, digits=4), 12), \n",
    "                rpad(round(f1, digits=4), 12),\n",
    "                Int(round(support)))\n",
    "    end\n",
    "    \n",
    "    # Overall metrics\n",
    "    total_correct = sum([cm[i,i] for i in 1:n_classes])\n",
    "    total_samples = sum(cm)\n",
    "    overall_accuracy = total_correct / total_samples\n",
    "    \n",
    "    println(\"-\"^80)\n",
    "    println(\"Overall Accuracy: \", round(overall_accuracy*100, digits=2), \"%\")\n",
    "    println(\"Total Samples: \", Int(round(total_samples)))\n",
    "    println(\"=\"^80)\n",
    "end\n",
    "\n",
    "# Analyze per-class performance for all models\n",
    "model_order = [\"ANN\", \"SVM\", \"DT\", \"kNN\", \"Ensemble\"]\n",
    "\n",
    "for model_name in model_order\n",
    "    if haskey(final_results, model_name)\n",
    "        cm = final_results[model_name][\"confusion_matrix\"]\n",
    "        analyze_confusion_matrix(cm, classes, model_name)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1fb93e",
   "metadata": {},
   "source": [
    "## 13. Conclusions\n",
    "\n",
    "In this study, we investigated the effectiveness of dimensionality reduction using PCA combined with various machine learning models for Human Activity Recognition (HAR).\n",
    "\n",
    "### 1. PCA Performance\n",
    "* **Dimensionality Reduction:** We successfully reduced the feature space from **561 original features** to **102 components**.\n",
    "* **Compression Rate:** This represents an **81.8% reduction** in data size while preserving **95% of the total variance**.\n",
    "* **Efficiency:** The training time for models like SVM was drastically reduced (approx. 10-15 seconds) compared to high-dimensional training, proving the efficiency of the approach for mobile/embedded environments.\n",
    "\n",
    "### 2. Best Model\n",
    "* **Winner:** The **Optimized Ensemble Model (ANN + SVM + kNN)**.\n",
    "* **Test Accuracy:** **93.32%** on the unseen Test Set.\n",
    "* **Key Insights:**\n",
    "    * The Ensemble outperformed all individual models (ANN: 93.04%, SVM: 92.20%), demonstrating the power of collective intelligence.\n",
    "    * It successfully corrected misclassifications in dynamic activities (Walking Upstairs/Downstairs) where individual models showed bias.\n",
    "    * The model showed high robustness against **Subject Independence**, dropping only ~4% from Cross-Validation results (97.3%) when tested on completely new subjects.\n",
    "\n",
    "### 3. Comparison with Baseline\n",
    "* **State-of-the-Art (Anguita et al.):** The original study achieved **96.4%** accuracy using all 561 features.\n",
    "* **Our Approach:** We achieved **93.32%** accuracy using only 102 features.\n",
    "* **Trade-off:** We accepted a minor **3% accuracy loss** in exchange for a massive **5x reduction in feature complexity**. This trade-off is highly advantageous for resource-constrained applications (e.g., real-time processing on smartphones).\n",
    "\n",
    "### 4. Future Improvements\n",
    "\n",
    "* **Explicit Gravity Feature Injection:** Confusion matrix analysis revealed that the majority of errors occur between 'SITTING' and 'STANDING' classes. Since PCA transforms features into a new space, the explicit vertical orientation information (Gravity-Z axis) might be diluted. Concatenating the raw `tGravityAcc-mean()-Z` feature to the PCA components could provide a direct signal to distinguish these static postures more effectively.\n",
    "\n",
    "* **kNN Optimization:** The current `k=1` setting led to overfitting on training subjects, causing a performance drop on the unseen test set. Increasing `k` (e.g., to 7 or 9) could improve generalization and robustness against subject-specific variations.\n",
    "\n",
    "* **Variance Threshold Adjustment:** Increasing the PCA variance threshold from 95% to **99% (approx. 179 components)** could potentially recover the missing 3% accuracy by preserving subtle micro-movements required to distinguish between similar static activities.\n",
    "\n",
    "* **Deep Learning Approaches:** Implementing 1D-CNNs or LSTMs directly on the raw sensor signals (instead of using hand-crafted features) could be explored to automatically extract optimal features and potentially surpass the current baseline performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia (ML1 RC) 1.12.0",
   "language": "julia",
   "name": "julia-_ml1-rc_-1.12"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
